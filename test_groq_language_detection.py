#!/usr/bin/env python3
"""
Test script to demonstrate Groq-based language detection for Indian languages.
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from utils.language_detector import detect_language_with_groq, detect_and_translate, get_indian_languages

def test_indian_language_detection():
    """Test Groq-based language detection for Indian languages."""
    
    # Test cases for Indian languages
    test_cases = [
        # Hindi
        ("рдирдорд╕реНрддреЗ, рдХреИрд╕реЗ рд╣реЛ рдЖрдк?", "hi"),
        ("рдХреНрдпрд╛ рдореБрдЭреЗ рдкреНрдпрд╛рд░ рдорд┐рд▓реЗрдЧрд╛?", "hi"),
        ("рдореЗрд░рд╛ рднрд╡рд┐рд╖реНрдп рдХреИрд╕рд╛ рд╣реЛрдЧрд╛?", "hi"),
        ("рдореИрдВ рдЕрдкрдиреА рдиреМрдХрд░реА рдореЗрдВ рд╕рдлрд▓ рд╣реЛрдКрдВрдЧрд╛?", "hi"),
        
        # Romanized Hindi
        ("mai aj kya kru?", "hi_rom"),
        ("kya haal hai?", "hi_rom"),
        ("mujhe pyar milega?", "hi_rom"),
        ("mera future kaisa hoga?", "hi_rom"),
        ("main apni job mein successful hoga?", "hi_rom"),
        ("aaj ka din kaisa rahega?", "hi_rom"),
        ("kya main apne dost se milunga?", "hi_rom"),
        ("meri shaadi kab hogi?", "hi_rom"),
        
        # Bengali
        ("ржиржорж╕рзНржХрж╛рж░, ржХрзЗржоржи ржЖржЫрзЗржи?", "bn"),
        ("ржЖржорж┐ ржХрж┐ ржнрж╛рж▓рзЛржмрж╛рж╕рж╛ ржкрж╛ржм?", "bn"),
        ("ржЖржорж╛рж░ ржнржмрж┐рж╖рзНржпрзО ржХрзЗржоржи рж╣ржмрзЗ?", "bn"),
        ("ржЖржорж┐ ржХрж┐ ржЖржорж╛рж░ ржХрзНржпрж╛рж░рж┐ржпрж╝рж╛рж░рзЗ рж╕ржлрж▓ рж╣ржм?", "bn"),
        
        # Telugu
        ("р░ир░ор░╕р▒Нр░Хр░╛р░░р░В, р░Ор░▓р░╛ р░Йр░ир▒Нр░ир░╛р░░р▒Б?", "te"),
        ("р░ир░╛р░Хр▒Б р░кр▒Нр░░р▒Зр░о р░╡р░╕р▒Нр░др▒Бр░Вр░жр░╛?", "te"),
        ("р░ир░╛ р░нр░╡р░┐р░╖р▒Нр░пр░др▒Нр░др▒Б р░Ор░▓р░╛ р░Йр░Вр░Яр▒Бр░Вр░жр░┐?", "te"),
        ("р░ир▒Зр░ир▒Б р░ир░╛ р░Хр▒Жр░░р▒Ар░░р▒НтАМр░▓р▒Л р░╡р░┐р░Ьр░пр░╡р░Вр░др░В р░Ер░╡р▒Бр░др░╛р░ир░╛?", "te"),
        
        # Tamil
        ("ро╡рогроХрпНроХроорпН, роОрокрпНрокроЯро┐ роЗро░рпБроХрпНроХро┐ро▒рпАро░рпНроХро│рпН?", "ta"),
        ("роОройроХрпНроХрпБ роХро╛родро▓рпН роХро┐роЯрпИроХрпНроХрпБрооро╛?", "ta"),
        ("роОройрпН роОродро┐ро░рпНроХро╛ро▓роорпН роОрокрпНрокроЯро┐ роЗро░рпБроХрпНроХрпБроорпН?", "ta"),
        ("роиро╛ройрпН роОройрпН родрпКро┤ро┐ро▓ро┐ро▓рпН ро╡рпЖро▒рпНро▒ро┐ рокрпЖро▒рпБро╡рпЗройро╛?", "ta"),
        
        # Marathi
        ("рдирдорд╕реНрдХрд╛рд░, рдХрд╕реЗ рдЖрд╣рд╛рдд?", "mr"),
        ("рдорд▓рд╛ рдкреНрд░реЗрдо рдорд┐рд│реЗрд▓ рдХрд╛?", "mr"),
        ("рдорд╛рдЭреЗ рднрд╡рд┐рд╖реНрдп рдХрд╕реЗ рдЕрд╕реЗрд▓?", "mr"),
        ("рдореА рдорд╛рдЭреНрдпрд╛ рдХрд░рд┐рдЕрд░рдордзреНрдпреЗ рдпрд╢рд╕реНрд╡реА рд╣реЛрдИрди рдХрд╛?", "mr"),
        
        # Gujarati
        ("ркиркорк╕рлНркдрлЗ, ркХрлЗрко ркЫрлЛ?", "gu"),
        ("ркоркирлЗ рккрлНрк░рлЗрко ркорк│рк╢рлЗ?", "gu"),
        ("ркорк╛рк░рлБркВ ркнрк╡рк┐рк╖рлНркп ркХрлЗрк╡рлБркВ рк░рк╣рлЗрк╢рлЗ?", "gu"),
        ("рк╣рлБркВ ркорк╛рк░рлА ркХрк╛рк░ркХрк┐рк░рлНркжрлАркорк╛ркВ рк╕рклрк│ ркеркИрк╢?", "gu"),
        
        # Kannada
        ("р▓ир▓ор▓╕р│Нр▓Хр▓╛р▓░, р▓╣р│Зр▓Чр│Ж р▓Зр▓жр│Нр▓жр│Ар▓░р▓┐?", "kn"),
        ("р▓ир▓ир▓Чр│Ж р▓кр│Нр▓░р│Ар▓др▓┐ р▓╕р▓┐р▓Чр│Бр▓др│Нр▓др▓жр│Жр▓пр│З?", "kn"),
        ("р▓ир▓ир│Нр▓и р▓нр▓╡р▓┐р▓╖р│Нр▓п р▓╣р│Зр▓Чр│Ж р▓Зр▓░р│Бр▓др│Нр▓др▓жр│Ж?", "kn"),
        ("р▓ир▓╛р▓ир│Б р▓ир▓ир│Нр▓и р▓╡р│Гр▓др│Нр▓др▓┐р▓Ьр│Ар▓╡р▓ир▓жр▓▓р│Нр▓▓р▓┐ р▓пр▓╢р▓╕р│Нр▓╡р▓┐р▓пр▓╛р▓Чр│Бр▓др│Нр▓др│Зр▓ир│Ж?", "kn"),
        
        # Malayalam
        ("р┤ир┤ор┤╕р╡Нр┤Хр┤╛р┤░р┤В, р┤Ор┤Щр╡Нр┤Щр┤ир╡Ж р┤Йр┤гр╡Нр┤Яр╡Н?", "ml"),
        ("р┤Ор┤ир┤┐р┤Хр╡Нр┤Хр╡Н р┤╕р╡Нр┤ир╡Зр┤╣р┤В р┤▓р┤нр┤┐р┤Хр╡Нр┤Хр╡Бр┤ор╡Л?", "ml"),
        ("р┤Ор┤ир╡Нр┤▒р╡Ж р┤нр┤╛р┤╡р┤┐ р┤Ор┤Щр╡Нр┤Щр┤ир╡Ж р┤Жр┤пр┤┐р┤░р┤┐р┤Хр╡Нр┤Хр╡Бр┤В?", "ml"),
        ("р┤Юр┤╛р╡╗ р┤Ор┤ир╡Нр┤▒р╡Ж р┤Хр┤░р┤┐р┤пр┤▒р┤┐р╡╜ р┤╡р┤┐р┤Ьр┤пр┤┐р┤Хр╡Нр┤Хр╡Бр┤ор╡Л?", "ml"),
        
        # Punjabi
        ("ри╕рид ри╕рйНри░рйА риЕриХри╛ри▓, риХри┐ри╡рйЗриВ ри╣рйЛ?", "pa"),
        ("риорйИриирйВрй░ рикри┐риЖри░ риори┐ри▓рйЗриЧри╛?", "pa"),
        ("риорйЗри░ри╛ ринри╡ри┐рй▒риЦ риХри┐ри╡рйЗриВ ри╣рйЛри╡рйЗриЧри╛?", "pa"),
        ("риорйИриВ риЖрикригрйЗ риХрйИри░рйАриЕри░ ри╡ри┐рй▒риЪ ри╕рилри▓ ри╣рйЛри╡ри╛риВриЧри╛?", "pa"),
        
        # Odia
        ("рмирморм╕рнНрмХрм╛рм░, рмХрм┐рмкрм░рм┐ рмЕрмЫрмирнНрмдрм┐?", "or"),
        ("рморнЛрмдрнЗ рмкрнНрм░рнЗрмо рморм┐рм│рм┐рмм?", "or"),
        ("рморнЛ рмнрммрм┐рм╖рнНрнЯрмд рмХрм┐рмкрм░рм┐ рм╣рнЗрмм?", "or"),
        ("рморнБрмБ рморнЛ рмХрнНрнЯрм╛рм░рм┐рмЕрм░рм░рнЗ рм╕рмлрм│ рм╣рнЗрммрм┐?", "or"),
        
        # Assamese
        ("ржиржорж╕рзНржХрж╛рз░, ржХрзЗржирзЗржХрзИ ржЖржЫрж╛?", "as"),
        ("ржорзЛржХ ржорз░ржо ржкрж╛ржо ржирзЗржХрж┐?", "as"),
        ("ржорзЛрз░ ржнрз▒рж┐рж╖рзНржпржд ржХрзЗржирзЗржХрзБрз▒рж╛ рж╣'ржм?", "as"),
        ("ржоржЗ ржорзЛрз░ ржХрз░рзНржоржЬрзАрз▒ржиржд рж╕ржлрж▓ рж╣'ржо ржирзЗржХрж┐?", "as"),
        
        # Urdu
        ("╪з┘Д╪│┘Д╪з┘Е ╪╣┘Д█М┌й┘Е╪М ┌й█М╪│█Т █Б█М┌║╪Я", "ur"),
        ("┌й█М╪з ┘Е╪м┌╛█Т ┘Е╪н╪и╪к ┘Е┘Д█Т ┌п█М╪Я", "ur"),
        ("┘Е█М╪▒╪з ┘Е╪│╪к┘В╪и┘Д ┌й█М╪│╪з █Б┘И┌п╪з╪Я", "ur"),
        ("┌й█М╪з ┘Е█М┌║ ╪з┘╛┘Ж█Т ┌й█М╪▒█М╪ж╪▒ ┘Е█М┌║ ┌й╪з┘Е█М╪з╪и █Б┘И┌║ ┌п╪з╪Я", "ur"),
        
        # Nepali
        ("рдирдорд╕реНрддреЗ, рдХрд╕рд░реА рд╣реБрдиреБрд╣реБрдиреНрдЫ?", "ne"),
        ("рдорд▓рд╛рдИ рдорд╛рдпрд╛ рдорд┐рд▓реНрдЫ?", "ne"),
        ("рдореЗрд░реЛ рднрд╡рд┐рд╖реНрдп рдХрд╕реНрддреЛ рд╣реБрдиреЗрдЫ?", "ne"),
        ("рдо рдореЗрд░реЛ рдХрд░рд┐рдпрд░рдорд╛ рд╕рдлрд▓ рд╣реБрдиреЗрдЫреБ?", "ne"),
        
        # English (for comparison)
        ("Hello, how are you?", "en"),
        ("Will I find love?", "en"),
        ("What does my future hold?", "en"),
        ("Will I be successful in my career?", "en"),
    ]
    
    print("ЁЯФо Testing Groq-Based Language Detection for Indian Languages")
    print("=" * 70)
    
    correct_detections = 0
    total_tests = len(test_cases)
    
    for i, (text, expected) in enumerate(test_cases, 1):
        print(f"\nTest {i}: '{text}'")
        print(f"Expected: {expected}")
        
        try:
            detected_lang, confidence = detect_language_with_groq(text)
            result = "тЬЕ" if detected_lang == expected else "тЭМ"
            print(f"Detected: {detected_lang} (confidence: {confidence:.2f}) {result}")
            
            if detected_lang == expected:
                correct_detections += 1
                
        except Exception as e:
            print(f"Error: {e}")
    
    print("\n" + "=" * 70)
    print("ЁЯУК RESULTS SUMMARY")
    print(f"Total Tests: {total_tests}")
    print(f"Correct Detections: {correct_detections}")
    print(f"Accuracy: {correct_detections/total_tests*100:.1f}%")
    
    # Show Indian languages supported
    indian_langs = get_indian_languages()
    print(f"\nЁЯЗоЁЯЗ│ Supported Indian Languages: {len(indian_langs)}")
    for code, name in indian_langs.items():
        print(f"  тАв {code}: {name}")

def test_translation_functionality():
    """Test translation functionality with Indian languages."""
    
    print("\nЁЯМР Testing Translation Functionality")
    print("=" * 50)
    
    test_texts = [
        ("рдирдорд╕реНрддреЗ, рдХреИрд╕реЗ рд╣реЛ рдЖрдк?", "hi"),
        ("ржиржорж╕рзНржХрж╛рж░, ржХрзЗржоржи ржЖржЫрзЗржи?", "bn"),
        ("р░ир░ор░╕р▒Нр░Хр░╛р░░р░В, р░Ор░▓р░╛ р░Йр░ир▒Нр░ир░╛р░░р▒Б?", "te"),
        ("ро╡рогроХрпНроХроорпН, роОрокрпНрокроЯро┐ роЗро░рпБроХрпНроХро┐ро▒рпАро░рпНроХро│рпН?", "ta"),
    ]
    
    for text, expected_lang in test_texts:
        print(f"\nOriginal ({expected_lang}): {text}")
        
        # Test detection and translation
        translated, detected_lang, confidence = detect_and_translate(text)
        print(f"Detected: {detected_lang} (confidence: {confidence:.2f})")
        print(f"Translated to English: {translated}")
        
        # Test back translation
        if detected_lang != 'en':
            from utils.language_detector import translate_back
            back_translated = translate_back(translated, detected_lang)
            print(f"Back translated: {back_translated}")

def test_short_texts():
    """Test detection with very short texts."""
    
    print("\nЁЯУЭ Testing Short Text Detection")
    print("=" * 50)
    
    short_texts = [
        ("рдирдорд╕реНрддреЗ", "hi"),
        ("ржиржорж╕рзНржХрж╛рж░", "bn"),
        ("р░ир░ор░╕р▒Нр░Хр░╛р░░р░В", "te"),
        ("ро╡рогроХрпНроХроорпН", "ta"),
        ("рдирдорд╕реНрдХрд╛рд░", "mr"),
        ("ркиркорк╕рлНркдрлЗ", "gu"),
        ("р▓ир▓ор▓╕р│Нр▓Хр▓╛р▓░", "kn"),
        ("р┤ир┤ор┤╕р╡Нр┤Хр┤╛р┤░р┤В", "ml"),
        ("ри╕рид ри╕рйНри░рйА риЕриХри╛ри▓", "pa"),
        ("рмирморм╕рнНрмХрм╛рм░", "or"),
        ("ржиржорж╕рзНржХрж╛рз░", "as"),
        ("╪з┘Д╪│┘Д╪з┘Е ╪╣┘Д█М┌й┘Е", "ur"),
        ("рдирдорд╕реНрддреЗ", "ne"),
    ]
    
    for text, expected in short_texts:
        print(f"\nText: '{text}'")
        try:
            detected_lang, confidence = detect_language_with_groq(text)
            result = "тЬЕ" if detected_lang == expected else "тЭМ"
            print(f"Expected: {expected}, Detected: {detected_lang} (confidence: {confidence:.2f}) {result}")
        except Exception as e:
            print(f"Error: {e}")

def test_romanized_hindi_detection():
    """Test Romanized Hindi detection specifically."""
    
    print("\nЁЯФд Testing Romanized Hindi Detection")
    print("=" * 50)
    
    romanized_hindi_tests = [
        ("mai aj kya kru?", "hi_rom"),
        ("kya haal hai?", "hi_rom"),
        ("mujhe pyar milega?", "hi_rom"),
        ("mera future kaisa hoga?", "hi_rom"),
        ("main apni job mein successful hoga?", "hi_rom"),
        ("aaj ka din kaisa rahega?", "hi_rom"),
        ("kya main apne dost se milunga?", "hi_rom"),
        ("meri shaadi kab hogi?", "hi_rom"),
        ("mujhe paise milege?", "hi_rom"),
        ("kya main accha hoga?", "hi_rom"),
        ("mera naam kya hai?", "hi_rom"),
        ("ghar mein kya chal raha hai?", "hi_rom"),
        ("kaam kaisa chal raha hai?", "hi_rom"),
        ("dost se milne ja raha hoon", "hi_rom"),
        ("pyar mein kya hoga?", "hi_rom"),
        ("shaadi kab hogi?", "hi_rom"),
        ("naukri milegi?", "hi_rom"),
        ("paise kahan se aayenge?", "hi_rom"),
        ("samay kaisa hai?", "hi_rom"),
        ("roz kya karta hai?", "hi_rom"),
        ("kal kya hoga?", "hi_rom"),
        ("parso kya plan hai?", "hi_rom"),
    ]
    
    correct_detections = 0
    total_tests = len(romanized_hindi_tests)
    
    for i, (text, expected) in enumerate(romanized_hindi_tests, 1):
        print(f"\nTest {i}: '{text}'")
        print(f"Expected: {expected}")
        
        try:
            detected_lang, confidence = detect_language_with_groq(text)
            result = "тЬЕ" if detected_lang == expected else "тЭМ"
            print(f"Detected: {detected_lang} (confidence: {confidence:.2f}) {result}")
            
            if detected_lang == expected:
                correct_detections += 1
                
        except Exception as e:
            print(f"Error: {e}")
    
    print("\n" + "=" * 50)
    print("ЁЯУК ROMANIZED HINDI RESULTS")
    print(f"Total Tests: {total_tests}")
    print(f"Correct Detections: {correct_detections}")
    print(f"Accuracy: {correct_detections/total_tests*100:.1f}%")

if __name__ == "__main__":
    test_indian_language_detection()
    test_romanized_hindi_detection()
    test_translation_functionality()
    test_short_texts()
    
    print("\nЁЯОЙ Groq-based language detection testing completed!")
    print("\nЁЯТб Key Features:")
    print("  тАв Uses the same Groq model as intent classification and tarot reading")
    print("  тАв Supports 13 major Indian languages + Romanized Hindi")
    print("  тАв Provides confidence scores for each detection")
    print("  тАв Includes fallback pattern detection for reliability")
    print("  тАв Maintains backward compatibility with existing code")
    print("  тАв NEW: Romanized Hindi (hi_rom) for informal Hindi chat") 